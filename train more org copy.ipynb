{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, LSTM\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'output (more)/train'\n",
    "val_dir = 'output (more)/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1968 images belonging to 41 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=24,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode='categorical',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 492 images belonging to 41 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=6,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3, 3),\n",
    "          activation='relu', input_shape=(128, 128, 1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "          activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.40))\n",
    "\n",
    "model.add(Dense(96, activation='relu'))\n",
    "model.add(Dropout(0.40))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(41, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 126, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 63, 63, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 31, 31, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 30752)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3936384   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 96)                12384     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                6208      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 41)                2665      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3967209 (15.13 MB)\n",
      "Trainable params: 3967209 (15.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/82 [==============================] - 80s 857ms/step - loss: 3.7219 - accuracy: 0.0274 - val_loss: 3.6372 - val_accuracy: 0.0732\n",
      "Epoch 2/100\n",
      "82/82 [==============================] - 69s 844ms/step - loss: 3.4656 - accuracy: 0.0503 - val_loss: 3.1465 - val_accuracy: 0.0366\n",
      "Epoch 3/100\n",
      "82/82 [==============================] - 65s 789ms/step - loss: 3.0915 - accuracy: 0.0874 - val_loss: 2.5437 - val_accuracy: 0.2033\n",
      "Epoch 4/100\n",
      "82/82 [==============================] - 45s 540ms/step - loss: 2.6343 - accuracy: 0.1692 - val_loss: 1.8243 - val_accuracy: 0.4268\n",
      "Epoch 5/100\n",
      "82/82 [==============================] - 40s 489ms/step - loss: 2.2551 - accuracy: 0.2373 - val_loss: 1.4341 - val_accuracy: 0.5650\n",
      "Epoch 6/100\n",
      "82/82 [==============================] - 36s 440ms/step - loss: 2.0198 - accuracy: 0.3105 - val_loss: 1.2142 - val_accuracy: 0.5732\n",
      "Epoch 7/100\n",
      "82/82 [==============================] - 37s 455ms/step - loss: 1.8204 - accuracy: 0.3455 - val_loss: 1.1068 - val_accuracy: 0.6585\n",
      "Epoch 8/100\n",
      "82/82 [==============================] - 37s 454ms/step - loss: 1.7277 - accuracy: 0.3730 - val_loss: 0.8783 - val_accuracy: 0.6789\n",
      "Epoch 9/100\n",
      "82/82 [==============================] - 37s 451ms/step - loss: 1.6420 - accuracy: 0.4136 - val_loss: 0.8838 - val_accuracy: 0.7236\n",
      "Epoch 10/100\n",
      "82/82 [==============================] - 36s 444ms/step - loss: 1.5731 - accuracy: 0.4309 - val_loss: 0.7673 - val_accuracy: 0.7317\n",
      "Epoch 11/100\n",
      "82/82 [==============================] - 39s 473ms/step - loss: 1.5124 - accuracy: 0.4395 - val_loss: 0.6860 - val_accuracy: 0.7805\n",
      "Epoch 12/100\n",
      "82/82 [==============================] - 38s 463ms/step - loss: 1.4473 - accuracy: 0.4593 - val_loss: 0.6657 - val_accuracy: 0.7561\n",
      "Epoch 13/100\n",
      "82/82 [==============================] - 37s 447ms/step - loss: 1.4557 - accuracy: 0.4563 - val_loss: 0.6614 - val_accuracy: 0.7683\n",
      "Epoch 14/100\n",
      "82/82 [==============================] - 36s 443ms/step - loss: 1.3594 - accuracy: 0.4964 - val_loss: 0.6671 - val_accuracy: 0.7846\n",
      "Epoch 15/100\n",
      "82/82 [==============================] - 37s 453ms/step - loss: 1.3460 - accuracy: 0.5005 - val_loss: 0.6144 - val_accuracy: 0.7805\n",
      "Epoch 16/100\n",
      "82/82 [==============================] - 37s 446ms/step - loss: 1.2764 - accuracy: 0.5239 - val_loss: 0.5460 - val_accuracy: 0.8577\n",
      "Epoch 17/100\n",
      "82/82 [==============================] - 37s 456ms/step - loss: 1.2738 - accuracy: 0.5371 - val_loss: 0.5105 - val_accuracy: 0.8374\n",
      "Epoch 18/100\n",
      "82/82 [==============================] - 38s 461ms/step - loss: 1.2154 - accuracy: 0.5407 - val_loss: 0.4891 - val_accuracy: 0.8130\n",
      "Epoch 19/100\n",
      "82/82 [==============================] - 37s 454ms/step - loss: 1.2335 - accuracy: 0.5340 - val_loss: 0.4526 - val_accuracy: 0.8902\n",
      "Epoch 20/100\n",
      "82/82 [==============================] - 38s 468ms/step - loss: 1.1567 - accuracy: 0.5716 - val_loss: 0.4272 - val_accuracy: 0.8618\n",
      "Epoch 21/100\n",
      "82/82 [==============================] - 46s 560ms/step - loss: 1.0922 - accuracy: 0.6082 - val_loss: 0.3904 - val_accuracy: 0.8821\n",
      "Epoch 22/100\n",
      "82/82 [==============================] - 35s 419ms/step - loss: 1.0903 - accuracy: 0.6092 - val_loss: 0.3472 - val_accuracy: 0.9146\n",
      "Epoch 23/100\n",
      "82/82 [==============================] - 35s 425ms/step - loss: 1.1335 - accuracy: 0.5971 - val_loss: 0.3898 - val_accuracy: 0.9065\n",
      "Epoch 24/100\n",
      "82/82 [==============================] - 38s 458ms/step - loss: 1.0362 - accuracy: 0.6250 - val_loss: 0.2903 - val_accuracy: 0.9187\n",
      "Epoch 25/100\n",
      "82/82 [==============================] - 36s 437ms/step - loss: 1.0509 - accuracy: 0.6194 - val_loss: 0.3504 - val_accuracy: 0.8862\n",
      "Epoch 26/100\n",
      "82/82 [==============================] - 35s 422ms/step - loss: 1.0530 - accuracy: 0.6225 - val_loss: 0.3141 - val_accuracy: 0.9187\n",
      "Epoch 27/100\n",
      "82/82 [==============================] - 37s 449ms/step - loss: 1.0110 - accuracy: 0.6316 - val_loss: 0.2513 - val_accuracy: 0.9593\n",
      "Epoch 28/100\n",
      "82/82 [==============================] - 37s 452ms/step - loss: 0.9803 - accuracy: 0.6402 - val_loss: 0.2357 - val_accuracy: 0.9512\n",
      "Epoch 29/100\n",
      "82/82 [==============================] - 38s 457ms/step - loss: 0.9776 - accuracy: 0.6428 - val_loss: 0.2502 - val_accuracy: 0.9390\n",
      "Epoch 30/100\n",
      "82/82 [==============================] - 36s 439ms/step - loss: 0.9316 - accuracy: 0.6636 - val_loss: 0.2382 - val_accuracy: 0.9472\n",
      "Epoch 31/100\n",
      "82/82 [==============================] - 37s 450ms/step - loss: 0.9431 - accuracy: 0.6641 - val_loss: 0.2524 - val_accuracy: 0.9431\n",
      "Epoch 32/100\n",
      "82/82 [==============================] - 37s 447ms/step - loss: 0.9108 - accuracy: 0.6723 - val_loss: 0.2128 - val_accuracy: 0.9878\n",
      "Epoch 33/100\n",
      "82/82 [==============================] - 37s 444ms/step - loss: 0.8816 - accuracy: 0.6875 - val_loss: 0.2330 - val_accuracy: 0.9431\n",
      "Epoch 34/100\n",
      "82/82 [==============================] - 38s 458ms/step - loss: 0.8451 - accuracy: 0.6885 - val_loss: 0.1915 - val_accuracy: 0.9878\n",
      "Epoch 35/100\n",
      "82/82 [==============================] - 36s 442ms/step - loss: 0.9084 - accuracy: 0.6789 - val_loss: 0.1881 - val_accuracy: 0.9593\n",
      "Epoch 36/100\n",
      "82/82 [==============================] - 36s 440ms/step - loss: 0.7930 - accuracy: 0.7048 - val_loss: 0.1637 - val_accuracy: 0.9837\n",
      "Epoch 37/100\n",
      "82/82 [==============================] - 36s 437ms/step - loss: 0.8679 - accuracy: 0.6961 - val_loss: 0.1589 - val_accuracy: 0.9878\n",
      "Epoch 38/100\n",
      "82/82 [==============================] - 38s 462ms/step - loss: 0.8345 - accuracy: 0.7027 - val_loss: 0.1802 - val_accuracy: 0.9390\n",
      "Epoch 39/100\n",
      "82/82 [==============================] - 36s 438ms/step - loss: 0.7967 - accuracy: 0.7063 - val_loss: 0.1913 - val_accuracy: 0.9797\n",
      "Epoch 40/100\n",
      "82/82 [==============================] - 39s 481ms/step - loss: 0.8027 - accuracy: 0.7154 - val_loss: 0.1490 - val_accuracy: 0.9837\n",
      "Epoch 41/100\n",
      "82/82 [==============================] - 41s 504ms/step - loss: 0.8180 - accuracy: 0.7160 - val_loss: 0.1308 - val_accuracy: 0.9919\n",
      "Epoch 42/100\n",
      "82/82 [==============================] - 44s 537ms/step - loss: 0.7750 - accuracy: 0.7210 - val_loss: 0.1362 - val_accuracy: 0.9919\n",
      "Epoch 43/100\n",
      "82/82 [==============================] - 40s 483ms/step - loss: 0.7800 - accuracy: 0.7109 - val_loss: 0.1496 - val_accuracy: 0.9878\n",
      "Epoch 44/100\n",
      "82/82 [==============================] - 39s 472ms/step - loss: 0.7686 - accuracy: 0.7388 - val_loss: 0.1171 - val_accuracy: 0.9919\n",
      "Epoch 45/100\n",
      "82/82 [==============================] - 35s 430ms/step - loss: 0.7274 - accuracy: 0.7342 - val_loss: 0.1235 - val_accuracy: 0.9837\n",
      "Epoch 46/100\n",
      "82/82 [==============================] - 36s 434ms/step - loss: 0.7761 - accuracy: 0.7398 - val_loss: 0.1378 - val_accuracy: 0.9797\n",
      "Epoch 47/100\n",
      "82/82 [==============================] - 39s 476ms/step - loss: 0.7048 - accuracy: 0.7520 - val_loss: 0.0930 - val_accuracy: 0.9837\n",
      "Epoch 48/100\n",
      "82/82 [==============================] - 38s 462ms/step - loss: 0.7321 - accuracy: 0.7409 - val_loss: 0.1121 - val_accuracy: 0.9837\n",
      "Epoch 49/100\n",
      "82/82 [==============================] - 33s 405ms/step - loss: 0.7541 - accuracy: 0.7276 - val_loss: 0.1090 - val_accuracy: 0.9919\n",
      "Epoch 50/100\n",
      "82/82 [==============================] - 36s 434ms/step - loss: 0.7439 - accuracy: 0.7470 - val_loss: 0.1091 - val_accuracy: 0.9878\n",
      "Epoch 51/100\n",
      "82/82 [==============================] - 33s 403ms/step - loss: 0.6809 - accuracy: 0.7673 - val_loss: 0.1009 - val_accuracy: 0.9837\n",
      "Epoch 52/100\n",
      "82/82 [==============================] - 34s 414ms/step - loss: 0.7029 - accuracy: 0.7490 - val_loss: 0.1106 - val_accuracy: 0.9675\n",
      "Epoch 53/100\n",
      "82/82 [==============================] - 33s 405ms/step - loss: 0.6991 - accuracy: 0.7541 - val_loss: 0.0945 - val_accuracy: 0.9959\n",
      "Epoch 54/100\n",
      "82/82 [==============================] - 34s 408ms/step - loss: 0.6681 - accuracy: 0.7632 - val_loss: 0.0979 - val_accuracy: 0.9878\n",
      "Epoch 55/100\n",
      "82/82 [==============================] - 33s 404ms/step - loss: 0.6798 - accuracy: 0.7622 - val_loss: 0.0999 - val_accuracy: 0.9919\n",
      "Epoch 56/100\n",
      "82/82 [==============================] - 34s 414ms/step - loss: 0.7232 - accuracy: 0.7586 - val_loss: 0.0855 - val_accuracy: 0.9837\n",
      "Epoch 57/100\n",
      "82/82 [==============================] - 35s 424ms/step - loss: 0.6802 - accuracy: 0.7632 - val_loss: 0.0692 - val_accuracy: 0.9919\n",
      "Epoch 58/100\n",
      "82/82 [==============================] - 36s 441ms/step - loss: 0.6264 - accuracy: 0.7871 - val_loss: 0.0729 - val_accuracy: 0.9837\n",
      "Epoch 59/100\n",
      "82/82 [==============================] - 36s 435ms/step - loss: 0.6584 - accuracy: 0.7724 - val_loss: 0.0862 - val_accuracy: 0.9919\n",
      "Epoch 60/100\n",
      "82/82 [==============================] - 37s 454ms/step - loss: 0.6173 - accuracy: 0.7851 - val_loss: 0.0963 - val_accuracy: 0.9837\n",
      "Epoch 61/100\n",
      "82/82 [==============================] - 36s 434ms/step - loss: 0.6455 - accuracy: 0.7749 - val_loss: 0.0671 - val_accuracy: 0.9919\n",
      "Epoch 62/100\n",
      "82/82 [==============================] - 34s 409ms/step - loss: 0.6028 - accuracy: 0.7886 - val_loss: 0.0458 - val_accuracy: 0.9959\n",
      "Epoch 63/100\n",
      "82/82 [==============================] - 36s 432ms/step - loss: 0.6158 - accuracy: 0.7866 - val_loss: 0.0730 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "82/82 [==============================] - 36s 442ms/step - loss: 0.6198 - accuracy: 0.7749 - val_loss: 0.0576 - val_accuracy: 0.9878\n",
      "Epoch 65/100\n",
      "82/82 [==============================] - 33s 406ms/step - loss: 0.6069 - accuracy: 0.7907 - val_loss: 0.0707 - val_accuracy: 0.9797\n",
      "Epoch 66/100\n",
      "82/82 [==============================] - 34s 413ms/step - loss: 0.6289 - accuracy: 0.7815 - val_loss: 0.0715 - val_accuracy: 0.9878\n",
      "Epoch 67/100\n",
      "82/82 [==============================] - 33s 400ms/step - loss: 0.6441 - accuracy: 0.7678 - val_loss: 0.0692 - val_accuracy: 0.9959\n",
      "Epoch 68/100\n",
      "82/82 [==============================] - 33s 406ms/step - loss: 0.6293 - accuracy: 0.7896 - val_loss: 0.0501 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "82/82 [==============================] - 33s 403ms/step - loss: 0.6262 - accuracy: 0.7846 - val_loss: 0.0581 - val_accuracy: 0.9837\n",
      "Epoch 70/100\n",
      "82/82 [==============================] - 33s 408ms/step - loss: 0.5961 - accuracy: 0.8074 - val_loss: 0.0534 - val_accuracy: 0.9919\n",
      "Epoch 71/100\n",
      "82/82 [==============================] - 34s 409ms/step - loss: 0.5917 - accuracy: 0.7947 - val_loss: 0.0417 - val_accuracy: 0.9959\n",
      "Epoch 72/100\n",
      "82/82 [==============================] - 33s 406ms/step - loss: 0.5500 - accuracy: 0.8100 - val_loss: 0.0403 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "82/82 [==============================] - 35s 422ms/step - loss: 0.5709 - accuracy: 0.7978 - val_loss: 0.0558 - val_accuracy: 0.9919\n",
      "Epoch 74/100\n",
      "82/82 [==============================] - 38s 458ms/step - loss: 0.5869 - accuracy: 0.8028 - val_loss: 0.0451 - val_accuracy: 0.9878\n",
      "Epoch 75/100\n",
      "82/82 [==============================] - 35s 432ms/step - loss: 0.5609 - accuracy: 0.8013 - val_loss: 0.0483 - val_accuracy: 0.9959\n",
      "Epoch 76/100\n",
      "82/82 [==============================] - 33s 408ms/step - loss: 0.5914 - accuracy: 0.8028 - val_loss: 0.0483 - val_accuracy: 0.9919\n",
      "Epoch 77/100\n",
      "82/82 [==============================] - 35s 425ms/step - loss: 0.5630 - accuracy: 0.8100 - val_loss: 0.0404 - val_accuracy: 0.9959\n",
      "Epoch 78/100\n",
      "82/82 [==============================] - 35s 426ms/step - loss: 0.5741 - accuracy: 0.8023 - val_loss: 0.0645 - val_accuracy: 0.9959\n",
      "Epoch 79/100\n",
      "82/82 [==============================] - 33s 407ms/step - loss: 0.5673 - accuracy: 0.7998 - val_loss: 0.0414 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "82/82 [==============================] - 34s 409ms/step - loss: 0.5432 - accuracy: 0.8181 - val_loss: 0.0432 - val_accuracy: 0.9959\n",
      "Epoch 81/100\n",
      "82/82 [==============================] - 34s 415ms/step - loss: 0.5562 - accuracy: 0.8064 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "82/82 [==============================] - 36s 441ms/step - loss: 0.5795 - accuracy: 0.8064 - val_loss: 0.0422 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "82/82 [==============================] - 37s 445ms/step - loss: 0.5090 - accuracy: 0.8227 - val_loss: 0.0323 - val_accuracy: 0.9919\n",
      "Epoch 84/100\n",
      "82/82 [==============================] - 37s 453ms/step - loss: 0.5164 - accuracy: 0.8186 - val_loss: 0.0497 - val_accuracy: 0.9919\n",
      "Epoch 85/100\n",
      "82/82 [==============================] - 34s 417ms/step - loss: 0.5298 - accuracy: 0.8262 - val_loss: 0.0366 - val_accuracy: 0.9959\n",
      "Epoch 86/100\n",
      "82/82 [==============================] - 38s 464ms/step - loss: 0.5021 - accuracy: 0.8267 - val_loss: 0.0353 - val_accuracy: 0.9959\n",
      "Epoch 87/100\n",
      "82/82 [==============================] - 33s 407ms/step - loss: 0.4943 - accuracy: 0.8257 - val_loss: 0.0345 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "82/82 [==============================] - 33s 406ms/step - loss: 0.5051 - accuracy: 0.8201 - val_loss: 0.0470 - val_accuracy: 0.9919\n",
      "Epoch 89/100\n",
      "82/82 [==============================] - 33s 406ms/step - loss: 0.5114 - accuracy: 0.8298 - val_loss: 0.0328 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "82/82 [==============================] - 33s 405ms/step - loss: 0.5229 - accuracy: 0.8186 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "82/82 [==============================] - 36s 439ms/step - loss: 0.4612 - accuracy: 0.8496 - val_loss: 0.0489 - val_accuracy: 0.9919\n",
      "Epoch 92/100\n",
      "82/82 [==============================] - 35s 424ms/step - loss: 0.4744 - accuracy: 0.8338 - val_loss: 0.0341 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "82/82 [==============================] - 34s 410ms/step - loss: 0.5069 - accuracy: 0.8288 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "82/82 [==============================] - 35s 428ms/step - loss: 0.5356 - accuracy: 0.8232 - val_loss: 0.0372 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "82/82 [==============================] - 38s 461ms/step - loss: 0.4879 - accuracy: 0.8277 - val_loss: 0.0409 - val_accuracy: 0.9959\n",
      "Epoch 96/100\n",
      "82/82 [==============================] - 34s 414ms/step - loss: 0.4812 - accuracy: 0.8389 - val_loss: 0.0283 - val_accuracy: 0.9959\n",
      "Epoch 97/100\n",
      "82/82 [==============================] - 34s 408ms/step - loss: 0.4815 - accuracy: 0.8369 - val_loss: 0.0451 - val_accuracy: 0.9919\n",
      "Epoch 98/100\n",
      "82/82 [==============================] - 34s 416ms/step - loss: 0.5102 - accuracy: 0.8227 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "82/82 [==============================] - 36s 443ms/step - loss: 0.4627 - accuracy: 0.8308 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "82/82 [==============================] - 36s 432ms/step - loss: 0.4532 - accuracy: 0.8476 - val_loss: 0.0229 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=100,\n",
    "                    validation_data=test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model_100.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "print('Model Saved')\n",
    "model.save_weights('model_100.h5')\n",
    "print('Weights saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8, 6])\n",
    "plt.plot(history.history['loss'], 'r', linewidth=2.0)\n",
    "plt.plot(history.history['val_loss'], 'b', linewidth=2.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'], fontsize=15)\n",
    "plt.xlabel('Epochs ', fontsize=16)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.title('Loss Curves', fontsize=16)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8, 6])\n",
    "plt.plot(history.history['accuracy'], 'r', linewidth=2.0)\n",
    "plt.plot(history.history['val_accuracy'], 'b', linewidth=2.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=15)\n",
    "plt.xlabel('Epochs ', fontsize=16)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.title('Accuracy Curves', fontsize=16)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "adbf25f6057a8929f58a5c88decc278f2bc49a76e25f3de3b15f2a6ee5d3b1b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
